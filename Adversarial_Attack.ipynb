{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown '19E0B_Cj2gCWSHiqI6wkFaHYXXXGVA0WR' -O data.zip\n",
    "!unzip ./data.zip\n",
    "!rm ./data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
    "\n",
    "* Explaination (optional)\n",
    "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
    "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
    "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
    "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# the mean and std are the calculated statistics from cifar_10 dataset\n",
    "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
    "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
    "\n",
    "# convert mean and std to 3-dimensional tensors for future operations\n",
    "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
    "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
    "\n",
    "epsilon = 8/255/std\n",
    "\n",
    "# Step size\n",
    "alpha = 0.8/255/std\n",
    "\n",
    "root = './data' # directory for storing benign images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.names = []\n",
    "        '''\n",
    "        data_dir\n",
    "        ├── class_dir\n",
    "        │   ├── class1.png\n",
    "        │   ├── ...\n",
    "        │   ├── class20.png\n",
    "        '''\n",
    "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
    "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
    "            self.images += images\n",
    "            self.labels += ([i] * len(images))\n",
    "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.transform(Image.open(self.images[idx]))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "    \n",
    "    def __getname__(self):\n",
    "        return self.names\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_set = AdvDataset(root, transform=transform)\n",
    "adv_names = adv_set.__getname__()\n",
    "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of model on benign images\n",
    "def epoch_benign(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    train_acc, train_loss = 0.0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yp = model(x)\n",
    "        loss = loss_fn(yp, y)\n",
    "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
    "        train_loss += loss.item() * x.shape[0]\n",
    "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(modellist, x, y, loss_fn, epsilon=epsilon):\n",
    "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
    "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
    "    loss = 0\n",
    "    for i in range(len(modellist)):\n",
    "        modellist[i].eval()\n",
    "        loss += loss_fn(modellist[i](x_adv), y) # calculate loss\n",
    "    loss.backward() # calculate gradient\n",
    "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.detach().sign()\n",
    "    \n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgsm(modellist, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=1000):\n",
    "    '''\n",
    "    initialize x_adv as original benign image x\n",
    "    write a loop of num_iter to represent the iterative times\n",
    "    for each loop\n",
    "        call fgsm with (epsilon = alpha) to obtain new x_adv\n",
    "        clip new x_adv back to [x-epsilon, x+epsilon]\n",
    "    '''\n",
    "    x_adv = x.detach().clone()\n",
    "    for i in range(num_iter):\n",
    "        x_adv = fgsm(modellist, x_adv, y, loss_fn, alpha)\n",
    "        x_adv = torch.max(torch.min(x_adv, x+epsilon), x-epsilon)\n",
    "    \n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Function\n",
    "\n",
    "- Recall\n",
    "    - ToTensor() can be seen as a function where $T(x) = x/255$.\n",
    "    - Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
    "    \n",
    "- Inverse function\n",
    "    - Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
    "    - Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
    "  \n",
    "- Special Noted\n",
    "    - ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
    "    - Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform adversarial attack and generate adversarial examples\n",
    "def gen_adv_examples(modellist, loader, attack, loss_fn):\n",
    "    train_acc_list, train_loss_list = [0.0]*len(modellist), [0.0]*len(modellist)\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_adv = attack(modellist, x, y, loss_fn) # obtain adversarial examples\n",
    "        for j in range(len(modellist)):\n",
    "            modellist[j].eval()\n",
    "            yp = modellist[j](x_adv)\n",
    "            loss = loss_fn(yp, y)\n",
    "            train_acc_list[j] += (yp.argmax(dim=1) == y).sum().item()\n",
    "            train_loss_list[j] += loss.item() * x.shape[0]\n",
    "        # store adversarial examples\n",
    "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
    "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
    "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
    "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
    "        advs = adv_ex if i == 0 else np.r_[advs, adv_ex]\n",
    "\n",
    "    return advs, train_acc_list, train_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory which stores adversarial examples\n",
    "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
    "    if os.path.exists(adv_dir) is not True:\n",
    "        _ = shutil.copytree(data_dir, adv_dir)\n",
    "    for example, name in zip(adv_examples, adv_names):\n",
    "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
    "        im.save(os.path.join(adv_dir, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = ptcv_get_model('resnet20_cifar10', pretrained=True).to(device)\n",
    "model_2 = ptcv_get_model('preresnet20_cifar10', pretrained=True).to(device)\n",
    "model_3 = ptcv_get_model('pyramidnet110_a48_cifar10', pretrained=True).to(device)\n",
    "model_4 = ptcv_get_model('seresnet20_cifar10', pretrained=True).to(device)\n",
    "model_5 = ptcv_get_model('diaresnet20_cifar10', pretrained=True).to(device)\n",
    "model_6 = ptcv_get_model('diapreresnet20_cifar10', pretrained=True).to(device)\n",
    "model_7 = ptcv_get_model('densenet40_k12_cifar10', pretrained=True).to(device)\n",
    "model_8 = ptcv_get_model('wrn16_10_cifar10', pretrained=True).to(device)\n",
    "model_9 = ptcv_get_model('nin_cifar10', pretrained=True).to(device)\n",
    "model_10 = ptcv_get_model('shakeshakeresnet20_2x16d_cifar10', pretrained=True).to(device)\n",
    "model_11 = ptcv_get_model('sepreresnet20_cifar10', pretrained=True).to(device)\n",
    "model_12 = ptcv_get_model('xdensenet40_2_k24_bc_cifar10', pretrained=True).to(device)\n",
    "model_13 = ptcv_get_model('ror3_56_cifar10', pretrained=True).to(device)\n",
    "model_14 = ptcv_get_model('rir_cifar10', pretrained=True).to(device)\n",
    "\n",
    "model_list = []\n",
    "model_list.append(model_1)\n",
    "model_list.append(model_2)\n",
    "model_list.append(model_3)\n",
    "model_list.append(model_4)\n",
    "model_list.append(model_5)\n",
    "model_list.append(model_6)\n",
    "model_list.append(model_7)\n",
    "model_list.append(model_8)\n",
    "model_list.append(model_9)\n",
    "model_list.append(model_10)\n",
    "model_list.append(model_11)\n",
    "model_list.append(model_12)\n",
    "model_list.append(model_13)\n",
    "model_list.append(model_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(len(model_list)):\n",
    "    benign_acc, benign_loss = epoch_benign(model_list[i], adv_loader, loss_fn)\n",
    "    print(f'num: {i}, benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_1\n",
    "# adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, fgsm, loss_fn)\n",
    "# print(f'fgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n",
    "\n",
    "# create_dir(root, 'fgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_examples, ifgsm_acc, ifgsm_loss = gen_adv_examples(model_list, adv_loader, ifgsm, loss_fn)\n",
    "for i in range(len(model_list)):\n",
    "    print(f'num: {i}, ifgsm_acc = {ifgsm_acc[i]/len(adv_loader.dataset):.5f}, ifgsm_loss = {ifgsm_loss[i]/len(adv_loader.dataset):.5f}')\n",
    "\n",
    "create_dir(root, 'en_ifgsm', adv_examples, adv_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd fgsm\n",
    "# !tar zcvf ../fgsm.tgz *\n",
    "# %cd ..\n",
    "\n",
    "%cd ifgsm\n",
    "!tar zcvf ../ifgsm.tgz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_1 # choose a model to visualize the performance\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "cnt = 0\n",
    "for i, cls_name in enumerate(classes):\n",
    "    path = f'{cls_name}/{cls_name}1.png'\n",
    "    # benign image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./data/{path}')\n",
    "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "    # adversarial image\n",
    "    cnt += 1\n",
    "    plt.subplot(len(classes), 4, cnt)\n",
    "    im = Image.open(f'./fgsm/{path}')\n",
    "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
    "    predict = logit.argmax(-1).item()\n",
    "    prob = logit.softmax(-1)[predict].item()\n",
    "    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(im))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
